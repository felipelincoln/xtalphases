{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch structures obtained by x-ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import textwrap\n",
    "import urllib\n",
    "import shutil\n",
    "import glob\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "chunk_runtime = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the sample\n",
    "Download the structures listed on the file`list.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of structures to get from list.txt \n",
    "# 584 is the max\n",
    "n_sample = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the following structures are going to be downloaded:\n",
      "3ato, 5v4g, 4h8y, 2ybj, 1h87, 4etd, 4lt0, 4tws, 3zvq, 3wu9\n"
     ]
    }
   ],
   "source": [
    "with open('list.txt') as f:\n",
    "    file = f.read()\n",
    "    sample = file.split('\\n')\n",
    "\n",
    "sample = sample[:n_sample]\n",
    "sample_str = ', '.join(sample)\n",
    "\n",
    "data_directory = f'{n_sample}-structures-{datetime.date.today()}'\n",
    "data_structure = [\n",
    "    {'dirname':'pdb',\n",
    "     'filename':'{query_id}_RCSB.pdb',\n",
    "     'url':'https://files.rcsb.org/download/{query_id}.pdb',\n",
    "    },\n",
    "    {'dirname':'pdb',\n",
    "     'filename':'{query_id}_REDO.pdb',\n",
    "     'url':'https://pdb-redo.eu/db/{query_id}/{query_id}_final.pdb',\n",
    "    },\n",
    "    {'dirname':'mtz',\n",
    "    'filename':'{query_id}_REDO.mtz',\n",
    "    'url':'https://pdb-redo.eu/db/{query_id}/{query_id}_final.mtz'\n",
    "    }\n",
    "]\n",
    "\n",
    "print('the following structures are going to be downloaded:')\n",
    "print(textwrap.fill(sample_str, 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download\n",
    "Downloading `.pdb` from RCSB and REDO, and `.mtz` from REDO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every structure were fully downloaded!\n",
      "\n",
      "duration:\t0:00:12.859177\n",
      "structures:\t10/10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.timedelta(seconds=time.time())\n",
    "\n",
    "# Directory structure\n",
    "data_directory_x = data_directory\n",
    "dir_num = 1\n",
    "while data_directory_x in os.listdir():\n",
    "    data_directory_x = data_directory + f'_{dir_num}'\n",
    "    dir_num += 1\n",
    "\n",
    "os.mkdir(data_directory_x)\n",
    "\n",
    "for each in data_structure:\n",
    "    if each['dirname'] not in os.listdir(data_directory_x):\n",
    "        subdir = f'{data_directory_x}/{each[\"dirname\"]}'\n",
    "        os.mkdir(subdir)\n",
    "\n",
    "# Downloading sample\n",
    "n_downloaded = n_sample\n",
    "def download_whole_data_structure(ID):\n",
    "    downloaded = []\n",
    "    with ThreadPoolExecutor() as thread_pool:\n",
    "        for each in data_structure:\n",
    "            request_url = each['url'].format(query_id=ID)\n",
    "            filename = each['filename'].format(query_id=ID)\n",
    "            path = f'{data_directory_x}/{each[\"dirname\"]}/{filename}'\n",
    "            download_request = thread_pool.submit(urllib.request.urlretrieve, request_url, path)\n",
    "            downloaded.append([filename, download_request])\n",
    "    exception_map = map(lambda row:[row[0], str(row[1].exception())], downloaded)\n",
    "    return [row for row in exception_map if row[1] != 'None']\n",
    "\n",
    "process_list = []\n",
    "with ProcessPoolExecutor() as process_pool:\n",
    "    for ID in sample:\n",
    "        request = process_pool.submit(download_whole_data_structure, ID)\n",
    "        process_list.append(request)\n",
    "\n",
    "exception_list = []\n",
    "for ID in process_list:\n",
    "    results = ID.result()\n",
    "    for each in results:\n",
    "        exception_list.append(each)\n",
    "    \n",
    "n_not_downloaded = len(set(row[0][:4] for row in exception_list))\n",
    "n_downloaded -= n_not_downloaded\n",
    "if n_not_downloaded > 0:\n",
    "    print(f'{n_not_downloaded} structures were not fully downloaded due to error!')\n",
    "else:\n",
    "    print('Every structure were fully downloaded!')\n",
    "\n",
    "end_time = datetime.timedelta(seconds=time.time())\n",
    "\n",
    "# report\n",
    "n = n_sample\n",
    "chunk_runtime['download'] = end_time - start_time\n",
    "\n",
    "print(f\"\\nduration:\\t{chunk_runtime['download']}\\nstructures:\\t{n_downloaded}/{n}\\n\")\n",
    "for ID in exception_list:\n",
    "      print(f'[{ID[1]}] {ID[0]} was not downloaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenix\n",
    "1. use the `.mtz` files to generate the REDO and RCSB phases with `phenix.reciprocal_space_arrays`.\n",
    "2. save the log from the `phenix.reciprocal_space_arrays` routine\n",
    "3. convert `.mtz` file to `.cif` using `phenix.mtz_as_cif`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_space_arrays(pdb_input, mtz_input, mtz_output, log_output):\n",
    "    first_instruction = f'phenix.reciprocal_space_arrays hkl_file={mtz_input} ' \\\n",
    "                        f'pdb_file={pdb_input} hendrickson_lattman_coefficients_label=None ' \\\n",
    "                        f'remove_f_obs_outliers=True bulk_solvent_and_scaling=True ' \\\n",
    "                        f'output_file_name={mtz_output} > {log_output}'\n",
    "    os.system(first_instruction)\n",
    "\n",
    "def mtz_as_cif(mtz_input, cif_output):\n",
    "    first_instruction = f'phenix.mtz_as_cif mtz_file={mtz_input} output_file={cif_output} ' \\\n",
    "                        'mtz_labels=\"FOBS SIGFOBS FMODEL PHIFMODEL FOM RESOLUTION\" ' \\\n",
    "                        'cif_labels=\"_refln.FOBS _refln.SIGFOBS _refln.FMODEL _refln.PHIMODEL _refln.FOM _refln.RESOL\"'    \n",
    "    os.system(first_instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running `phenix.reciprocal_space_arrays`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:\t0:01:17.770954\n"
     ]
    }
   ],
   "source": [
    "sample = set(sample)\n",
    "exception_list = set(x[0][:4] for x in exception_list)\n",
    "sample = sample - exception_list\n",
    "\n",
    "# define the phenix log output dirname\n",
    "log_output_dirname = 'phenix'\n",
    "\n",
    "mtz_dir = data_directory_x + f'/{data_structure[2][\"dirname\"]}/'\n",
    "mtz_input_template = mtz_dir + data_structure[2]['filename']\n",
    "mtz_files = [mtz_input_template.format(query_id=each) for each in sample]\n",
    "\n",
    "mtz_output_dirname = mtz_dir\n",
    "mtz_output_template = mtz_output_dirname + '{query_id}_{source}_temporary.mtz'\n",
    "\n",
    "log_output_dirname = f'{data_directory_x}/{log_output_dirname}/'\n",
    "log_output_template = log_output_dirname + '{query_id}_{source}_phenix.log'\n",
    "os.mkdir(log_output_dirname)\n",
    "\n",
    "pdb_structure = data_structure[0]\n",
    "pdb_input_template = f\"{data_directory_x}/{pdb_structure['dirname']}\" + '/{query_id}_{source}.pdb'\n",
    "\n",
    "start_time = datetime.timedelta(seconds=time.time())\n",
    "\n",
    "source_structure = ['RCSB', 'REDO']\n",
    "process_list = []\n",
    "with ProcessPoolExecutor() as process_pool:\n",
    "    for src in source_structure: \n",
    "        for ID in sample:\n",
    "            pdb_input = pdb_input_template.format(query_id=ID, source=src)\n",
    "            mtz_input = mtz_input_template.format(query_id=ID)\n",
    "            mtz_output = mtz_output_template.format(query_id=ID, source=src)\n",
    "            log_output = log_output_template.format(query_id=ID, source=src)\n",
    "            \n",
    "            request = process_pool.submit(reciprocal_space_arrays, pdb_input, mtz_input, mtz_output, log_output)\n",
    "            process_list.append(request)\n",
    "    \n",
    "end_time = datetime.timedelta(seconds=time.time())\n",
    "\n",
    "#report\n",
    "chunk_runtime['reciprocal_space_arrays'] = end_time - start_time\n",
    "\n",
    "print(f\"duration:\\t{chunk_runtime['reciprocal_space_arrays']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next task: convert the `.mtz` files to `.cif`  \n",
    "Defining the directory structure for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running `phenix.mtz_as_cif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:\t0:00:33.854936\n"
     ]
    }
   ],
   "source": [
    "# define the output dirname\n",
    "cif_output_dirname = 'phases'\n",
    "cif_output_dirname = f'{data_directory_x}/{cif_output_dirname}/'\n",
    "cif_output_template = cif_output_dirname + '{query_id}_{source}_phases.cif'\n",
    "os.mkdir(cif_output_dirname)\n",
    "mtztemporary_input_template = mtz_output_template\n",
    "\n",
    "\n",
    "start_time = datetime.timedelta(seconds=time.time())\n",
    "\n",
    "source_structure = ['RCSB', 'REDO']\n",
    "\n",
    "with ProcessPoolExecutor() as process_pool:\n",
    "    for src in source_structure: \n",
    "        for ID in sample:\n",
    "            mtz_input = mtztemporary_input_template.format(query_id=ID, source=src)\n",
    "            cif_output = cif_output_template.format(query_id=ID, source=src)\n",
    "            request = process_pool.submit(mtz_as_cif, mtz_input, cif_output)\n",
    "            \n",
    "end_time = datetime.timedelta(seconds=time.time())\n",
    "\n",
    "#report\n",
    "chunk_runtime['mtz_as_cif'] = end_time - start_time\n",
    "print(f\"duration:\\t{chunk_runtime['mtz_as_cif']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally, move all relevant data to the `data/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"data\")\n",
    "\n",
    "for file in glob.glob(data_directory_x + r'/pdb/*_RCSB.pdb'):\n",
    "    shutil.copy(file, \"data/\")\n",
    "\n",
    "for file in glob.glob(data_directory_x + r'/phases/*_REDO_phases.cif'):\n",
    "    shutil.copy(file, \"data/\")\n",
    "\n",
    "shutil.rmtree(data_directory, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
